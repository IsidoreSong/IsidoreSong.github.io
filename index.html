<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Isidore Song</title>
    <meta name="author" content="Isidore Song">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="assets/icon.png" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <style>
      /* Modal styles */
      .modal {
        display: none; 
        position: fixed; 
        z-index: 1001; 
        padding-top: 100px; 
        left: 0;
        top: 0;
        width: 100%; 
        height: 100%; 
        overflow: auto; 
        background-color: rgba(0,0,0,0.9);
        text-align: center;
      }
      .modal-content {
        margin: auto;
        display: block;
        width: 80%;
        max-width: 700px;
      }
      .modal-content {
        animation-name: zoom;
        animation-duration: 0.6s;
      }
      @keyframes zoom {
        from {transform:scale(0)}
        to {transform:scale(1)}
      }
      .close {
        position: absolute;
        top: 15px;
        right: 35px;
        color: #f1f1f1;
        font-size: 40px;
        font-weight: bold;
        transition: 0.3s;
      }
      .close:hover,
      .close:focus {
        color: #bbb;
        text-decoration: none;
        cursor: pointer;
      }
      .publication-image {
        cursor: pointer;
      }
    </style>
  </head>
  <body>
    <!-- The Modal -->
    <div id="myModal" class="modal">
      <span class="close">&times;</span>
      <img class="modal-content" id="img01">
    </div>

    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Youzhe Song (Isidore)
                </p>
                <p>
                  <!-- I am a Master's student at East China Normal University, advised by Prof. Feng Wang. -->
                  My research centers on building AI that not only performs well but also reasons in a way that is <strong>intuitive and trustworthy</strong> to humans.
                  <br><br>
                  I focus on two core questions:
                  <br>
                  1) How can we build models that have a <strong>human-intuitive, stepwise, and organic reasoning trajectory</strong>?
                  <br>
                  2) How can models <strong>understand and align information from different sources</strong> (e.g., images and text) in a human-like manner?
                </p>
                <p style="text-align:center">
                  <a href="mailto:yanfengz@outlook.com">âœ‰ï¸ yanfengz@outlook.com</a>
                  <br>
                  ğŸ“ Zhangjiang, Pudong, Shanghai, China
                </p>
                <p style="text-align:center">
                  <a href="CV/2026Fall_Youzhe_Song_CV_phd.html">ğŸ”— CV</a> (<a href="CV/2026Fall_Youzhe_Song_CV_phd.pdf">ğŸ“„ PDF</a>) &nbsp;/&nbsp;
                  <a href="SOP/SOP.html">ğŸ”— SOP</a> (<a href="SOP/SOP.pdf">ğŸ“„ PDF</a>) &nbsp;/&nbsp;
                  <a href="https://github.com/IsidoreSong">ğŸ’» Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="assets/Youzhe Song.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="assets/Youzhe Song.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <h2>Research</h2>
            <tr>
              <td style="width:100%;vertical-align:middle">
                <p>
                  My Ph.D. research plan is built on my experience in mechanism design and reflections on human cognition. I aim to focus on two primary capabilities of large models:
                </p>
                <p>
                  <strong>1. Building a Unified Semantic Space:</strong> My first goal is to study how to effectively map diverse information into a unified, interpretable latent space. This goes beyond cross-modal mappingâ€”it underpins logical reasoning. I believe that efficient cross-modal semantic alignment is a first step toward foundational models that can comprehensively understand the world.
                </p>
                <p>
                  <strong>2. Realizing Structured Reasoning in Latent Space:</strong> After achieving semantic alignment, my next goal is to design structured, chain-of-thought-like reasoning trajectories within this unified latent space. I want models not only to produce answers but also to present a decomposable and traceable reasoning process.
                </p>
              </td>
            </tr>
          </tbody></table>
          <br>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <h2>Education</h2>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="assets/ECNU.png" alt="ECNU Logo" width="100" style="display: block; margin-left: auto; margin-right: auto;"></td>
              <td width="75%" valign="center">
                <strong><span class="papertitle">East China Normal University</span></strong> (Project 985)
                <br> <em>Sept 2021 â€“ June 2024</em><br>  <strong>M.S. in Computer Science and Technology</strong>
                <br> GPA: 3.77/4.00 (Top 5%); Admitted via recommendation (waiver of entrance exam).
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="assets/Donghua_University_logo.png" alt="Donghua University Logo" width="100" style="display: block; margin-left: auto; margin-right: auto;"></td>
              <td width="75%" valign="center">
                <strong><span class="papertitle">Donghua University</span></strong> (Project 211)
                <br> <em>Sept 2017 â€“ June 2021</em><br>  <strong>B.S. in Computer Science and Technology</strong>
                <br> GPA: 4.01/4.30; Rank: 2/180; Outstanding Graduate.
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="assets/Purdue_University_Northwest.svg" alt="Purdue University Northwest Logo" width="100" style="display: block; margin-left: auto; margin-right: auto;"></td>
              <td width="75%" valign="center">
                <strong><span class="papertitle">Purdue University Northwest</span></strong>
                <br> <em>Aug 2019 â€“ Aug 2020</em><br>  <strong>Exchange Student &amp; Research Assistant</strong>
                <br> GPA: 3.90/4.00; Awarded full CSC scholarship; 1st Place, Notre Dame Data Hackathon.
              </td>
            </tr>
          </tbody></table>
          <br>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <h2>Publications</h2>
            <tr style="padding:20px;border-spacing:20px;">
              <td style="padding:20px;width:40%;vertical-align:middle">
                <img src="assets/data/CoReFace.png" alt="CoReFace Project" width="100%" class="publication-image" style="border-style: none; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.3); transition: filter 0.3s ease;">
              </td>
              <td width="60%" valign="middle">
                <a href="https://doi.org/10.1016/j.patcog.2024.110483">
                  <span class="papertitle">CoReFace: Sample-guided Contrastive Regularization for Deep Face Recognition</span>
                </a>
                <br>
                <strong>Youzhe Song</strong>, Feng Wang
                <br>
                <em>Pattern Recognition (PR), 2024</em>
                <br>
                <a href="https://doi.org/10.1016/j.patcog.2024.110483">Paper</a> (<a href="assets/data/CoReFace_PR_revised2.pdf">PDF</a>) /
                <a href="https://github.com/IsidoreSong/CoreFace">Code</a>
                <p></p>
                <p>A framework using contrastive learning as a regularizer to learn a more discriminative feature space, increasing the similarity margin for positive/negative pairs by 15% and achieving SOTA performance.</p>
              </td>
            </tr>
            <tr style="padding:20px;border-spacing:20px;">
              <td style="padding:20px;width:40%;vertical-align:middle">
                <img src="assets/data/QGFace.png" alt="QGFace Project" width="100%" class="publication-image" style="border-style: none; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.3); transition: filter 0.3s ease;">
              </td>
              <td width="60%" valign="middle">
                <a href="https://arxiv.org/abs/2312.17494">
                  <span class="papertitle">QGFace: Quality-Guided Joint Training For Mixed-Quality Face Recognition</span>
                </a>
                <br>
                <strong>Youzhe Song</strong>, Feng Wang
                <br>
                <em>IEEE International Conference on Automatic Face and Gesture Recognition (FG), 2024</em>
                <br>
                <a href="https://arxiv.org/abs/2312.17494">Paper</a> (<a href="assets/data/QGFace.pdf">PDF</a>) /
                <a href="https://github.com/IsidoreSong/QGFace">Code</a>
                <p></p>
                <p>A unified, single-encoder architecture with a quality-aware strategy to address the real-world issue of training a single model on heterogeneous-quality data, reaching SOTA on mixed-quality benchmarks.</p>
              </td>
            </tr>
          </tbody></table>
          <br>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <h2>Industry Experience</h2>
            <tr>
              <td style="padding:20px;width:15%;vertical-align:middle"><img src="assets/wwec.jpg" alt="WWEC Logo" width="50" style="display: block; margin-left: auto; margin-right: auto;"></td>
              <td width="85%" valign="center">
                <strong><a href="https://www.wwec820.com/"><span class="papertitle">Worldwide Educators Conference (WWEC)</span></a></strong>
                <br> <em>June 2024 - Present</em><br>  <strong>Technical Manager</strong>
                <br> Managed technical associations and developed an automated tool to generate 1000+ custom conference assets, saving an estimated 100+ hours of manual design work.
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:15%;vertical-align:middle"><img src="assets/qiyuan.jpg" alt="KeyoneAI Logo" width="50" style="display: block; margin-left: auto; margin-right: auto;"></td>
              <td width="85%" valign="center">
                <strong><a href="#"><span class="papertitle">Shanghai KeyoneAI Technology Co., Ltd.</span></a></strong>
                <br> <em>May 2023 - Oct 2023</em><br>  <strong>AI Full-Stack Developer Intern</strong>
                <br> Engineered a full-stack design tool by fine-tuning Stable Diffusion with LoRA and ControlNet to enable intuitive, controllable features like text-to-image and inpainting.
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:15%;vertical-align:middle"></td>
              <td width="85%" valign="center">
                <strong><a href="#"><span class="papertitle">Shanghai Feifan Technology Co., Ltd.</span></a></strong>
                <br> <em>May 2021 - Aug 2021</em><br>  <strong>AI Algorithm Intern</strong>
                <br> Developed a fashion aesthetics recommendation system leading to a 20% inventory reduction for the client by building a color block classification model and a rule-based engine.
              </td>
            </tr>
          </tbody></table>
          <br>

<h2 id="interests">Interests</h2>
<p>ğŸ¤ Recitation | ğŸ¥Œ Curling | ğŸï¸ Outdoor Activities | ğŸ§˜ Meditation | ğŸ“š Reading | ğŸ› ï¸ Exploring New Toolchains</p>

<h2 id="reading-list">Reading List</h2>
<p>Each line in the list is presented with the date, book title, and author. An asterisk (*) at the end indicates a key book.</p>
<p>Books not read on WeChat Read cannot be traced back in time. After experiencing consecutive submission failures in mid-2023, my inner confusion and helplessness erupted, and I began reading a large number of spiritual books, seeking personal life integration. In recent years, I have made breakthroughs in my personal mindset. If we only know too much knowledge, we cannot live this life well. So after overcoming internal friction, I read fewer books.</p>

<h3>Undated Books (Mostly from university and before)</h3>
<ul>
    <li>The Power, The Magic, Hero (by Rhonda Byrne)</li>
    <li>â­ <strong>ä¹é˜³å‰‘åœ£ (Nine Yang Sword Saint)</strong></li>
    <li>è¶…ç¥æœºæ¢°å¸ˆ (The Legendary Mechanic)</li>
    <li>â­ <strong>ä¸‰ä½“ (The Three-Body Problem)</strong></li>
    <li>é•¿ç”Ÿå¸å­ (Longevity Emperor's Son)</li>
    <li>ä¿®çœŸç•Œè´¥ç±» (Scum of the Cultivation World)</li>
    <li>æ´»æ³• (Ikigai)</li>
    <li>é»æ˜ä¹‹å‰‘ (Sword of Dawn)</li>
    <li>æ¯›æ³½ä¸œé€‰é›† (Selected Works of Mao Zedong)</li>
    <li>ç‚ä½“æºæµ (The Origin of Qi)</li>
    <li>â­ <strong>æ·±å¥¥çš„ç®€æ´ (Profound Simplicity)</strong></li>
    <li>â­ <strong>ä»€ä¹ˆæ˜¯æŠ€æœ¯ (The Question Concerning Technology)</strong></li>
    <li>å°é€»è¾‘ (The Shorter Logic)</li>
    <li>â­ <strong>ç¦…æµ·è ¡æµ‹ (Measuring the Ocean of Zen with a Conch)</strong></li>
    <li>â­ <strong>çˆµè¿¹ (L.O.R.D: Legend of Ravaging Dynasties)</strong></li>
    <li>å°æ—¶ä»£ï¼ˆI-IVï¼‰(Tiny Times)</li>
    <li>ç¥å°ç‹åº§ (Throne of Seal)</li>
</ul>

<h3>Reading Journey</h3>
<h4>2025</h4>
<ul>
    <li>â­ <strong>2025/4 ç§˜å¯† (The Secret) (Second time)</strong></li>
</ul>
<h4>2024</h4>
<ul>
    <li>â­ <strong>2024/10 è¢«è®¨åŒçš„å‹‡æ°” (The Courage to Be Disliked)</strong></li>
    <li>2024/9 è°è¯´æˆ‘ä¸å¯ä»¥ (Who Says I Can't)</li>
    <li>â­ <strong>2024/8 è¥¿è¥¿å¼—ç¥è¯ (The Myth of Sisyphus) by Albert Camus</strong></li>
    <li>â­ <strong>2024/2 å½“ä¸‹çš„åŠ›é‡ (The Power of Now) by Eckhart Tolle</strong></li>
    <li>â­ <strong>2024/1 ä¿®è¡Œæ˜ç†æ‰‹å†Œ (Manual for Practice and Understanding Truth)</strong></li>
    <li>2024/1 å¿«ä¹ç»ˆææŒ‡å— (The Ultimate Guide to Happiness)</li>
    <li>2024/1 é›¶æé™ (Zero Limits)</li>
</ul>
<h4>2023</h4>
<ul>
    <li>2023/12 ä½›é“ä¸€å¦‚é“å¾·ç»ä¿®è®¢æœ¬ (Buddhism and Taoism as One: Revised Tao Te Ching)</li>
    <li>2023/9 ä¸ç¾çš„çµé­‚ (The Untethered Soul)</li>
    <li>2023/9 ç²¾åŠ›ç®¡ç† (The Power of Full Engagement)</li>
    <li>2023/9 åœ†è§‰ç»ç•¥è¯´ (Sutra of Perfect Enlightenment Explained) by Nan Huai-Chin</li>
    <li>2023/6 æ— é—¨å…³ (The Gateless Gate)</li>
    <li>2023/6 ä½›æ³•ä¸ä¹‰ç† (The Dharma and Principles) by Nan Huai-Chin</li>
    <li>2023/6 ç¦…æµ·è ¡æµ‹ï¼ˆè¯­è¯‘ï¼‰(Measuring the Ocean of Zen with a Conch - annotated)</li>
    <li>2023/3 ç»´æ‘©è¯˜çš„èŠ±é›¨æ¼«å¤© (Vimalakirti's Flower Rain) by Nan Huai-Chin</li>
    <li>2023/3 å†…å‘è€…ä¼˜åŠ¿ (The Introvert Advantage)</li>
</ul>
<h4>2022</h4>
<ul>
    <li>â­ <strong>2022/11 å¤§æ‰‹å°æµ…é‡Š (A Brief Explanation of Mahamudra) by Master Yuanyin</strong></li>
    <li>2022/11 å®šæ…§åˆä¿® (Initial Practice of Samatha-Vipassana)</li>
    <li>2022/11 ç‘œä¼½å¸ˆåœ°è®ºÂ·å£°é—»åœ°è®²å½• (Lectures on the Yogacarabhumi-sastra)</li>
    <li>2022/11 äººç”Ÿçš„èµ·ç‚¹å’Œç»ˆç‚¹ (The Start and End of Life)</li>
    <li>2022/10 å®—é•œå½•ç•¥è®² (Brief Lectures on the Zongjing Lu)</li>
    <li>2022/10 è¯å¸ˆç»çš„æµä¸–è§‚ (The World-Saving View of the Medicine Buddha Sutra)</li>
    <li>2022/10 ç­”é—®é’å£®å¹´å‚ç¦…è€… (Answering Young Chan Practitioners)</li>
    <li>2022/10 ç¦…ä¸ç”Ÿå‘½çš„è®¤çŸ¥åˆè®² (Introduction to Zen and the Cognition of Life)</li>
    <li>2022/10 é™åä¿®é“ä¸é•¿ç”Ÿä¸è€ (Meditation and Immortality)</li>
    <li>2022/10 å¦‚ä½•ä¿®æ­£ä½›æ³• (How to Cultivate Buddhist Dharma)</li>
    <li>2022/6 å¤§å”å…´äº¡ä¸‰ç™¾å¹´ (Three Hundred Years of the Rise and Fall of the Tang Dynasty)</li>
    <li>2022/5 ç”Ÿå‘½è¿›åŒ–çš„è·ƒå‡ (The Leap of Life's Evolution)</li>
    <li>2022/5 ä¸­å›½Â·æ”¿é“ (China's Political Way)</li>
    <li>â­ <strong>2022/2 å¤§å¥‰æ‰“æ›´äºº (Guardians of the Dafeng)</strong></li>
    <li>2022/1 çªƒæ˜ (Qie Ming)</li>
</ul>
<h4>2021</h4>
<ul>
    <li>2021/12 æ´¥å·´å¤šå£è¿°å² (The Zimbardo Oral History)</li>
    <li>2021/4 ä¿®çœŸå››ä¸‡å¹´ (Forty Millenniums of Cultivation)</li>
    <li>2021/4 ä¸€å¥é¡¶ä¸€ä¸‡å¥ (One Sentence is Worth Ten Thousand)</li>
    <li>2021/4 æ–­èˆç¦» (Dan-sha-ri)</li>
    <li>â­ <strong>2021/3 è¯¡ç§˜ä¹‹ä¸» (Lord of Mysteries) by çˆ±æ½œæ°´çš„ä¹Œè´¼</strong></li>
    <li>2021/3 é‡å£å‘³å¿ƒç†å­¦ (Provocative Psychology)</li>
    <li>2021/2 å­ºå­å¸ (The Child Emperor)</li>
    <li>2021/2 å¤§ç§¦å¸å›½(12å†Œ) (The Great Qin Empire series)</li>
</ul>
<h4>2020</h4>
<ul>
    <li>2020/12 äº”ä¸‡å¹´ä¸­å›½å² (Fifty Thousand Years of Chinese History)</li>
    <li>2020/11 ä¹¦å‰‘æ©ä»‡å½• (The Book and the Sword) by Jin Yong</li>
    <li>2020/11 ç‰›å¥¶å¯ä¹ç»æµå­¦ (Milk and Cola Economics)</li>
    <li>2020/9 é“æ—æ ¼é›·çš„ç”»åƒ (The Picture of Dorian Gray)</li>
    <li>2020/9 è®©æˆé•¿å¸¦ä½ ç©¿é€è¿·èŒ« (Let Growth Guide You Through Confusion) by Yu Minhong</li>
    <li>2020/9 æ„¿ä½ çš„é’æ˜¥ä¸è´Ÿæ¢¦æƒ³ (May Your Youth Live Up to Your Dreams) by Yu Minhong</li>
    <li>2020/8 å¤©è¡Œå¥ (Tian Xing Jian)</li>
    <li>2020/8 é¹¿é¼è®° (The Deer and the Cauldron)</li>
    <li>2020/8 å¤§æ˜äº¡å›½å²ï¼šå´‡ç¥¯çš‡å¸ä¼  (History of the Ming Dynasty's Fall: Biography of Emperor Chongzhen)</li>
    <li>2020/7 å ‚å‰è¯ƒå¾· (Don Quixote)</li>
    <li>2020/6 ç™¾å¹´å­¤ç‹¬ (One Hundred Years of Solitude)</li>
    <li>â­ <strong>2020/6 äºµæ¸ (Blasphemy)</strong></li>
    <li>2020/6 ç”Ÿæ´»æ˜¯å¾ˆå¥½ç©çš„ (Life is Fun)</li>
    <li>2020/6 ä¸–é—´æ‰€æœ‰ç›¸é‡éƒ½æ˜¯ä¹…åˆ«é‡é€¢ (All Encounters in the World Are Reunions After a Long Separation)</li>
    <li>2020/6 é¼ ç–« (The Plague) by Albert Camus</li>
    <li>2020/6 æµ·å¥¥åé¢„è¨€ (The Thiaoouba Prophecy)</li>
    <li>â­ <strong>2020/5 æ´»ç€ (To Live)</strong></li>
    <li>2020/5 ç½—ç”Ÿé—¨ (Rashomon)</li>
    <li>â­ <strong>2020/5 å±€å¤–äºº (The Stranger) by Albert Camus</strong></li>
    <li>2020/5 åˆ«ç¬‘ï¼Œè¿™æ˜¯å¤§æ¸…æ­£å² (Don't Laugh, This is the Official History of the Qing Dynasty)</li>
    <li>2020/5 é«˜æƒ…å•†èŠå¤©æœ¯ (The Art of High EQ Chat)</li>
    <li>2020/5 ä¸‰é‡é—¨ (Triple Door)</li>
    <li>2020/5 è¿‡å¾—åˆšå¥½ (Just Right)</li>
    <li>2020/4 é›ªä¸­æ‚åˆ€è¡Œ (Sword Snow Stride)</li>
    <li>2020/2 ä¸ç¥åˆä¸€ (Communion with God)</li>
    <li>2020/2 ä¸ç¥ä¸ºå‹ (Friendship with God)</li>
    <li>â­ <strong>2020/2 ä¸ç¥å¯¹è¯I-III (Conversations with God)</strong></li>
    <li>2020/1 å¨±ä¹è‡³æ­» (Amusing Ourselves to Death)</li>
    <li>â­ <strong>2020/1 éæš´åŠ›æ²Ÿé€š (Nonviolent Communication)</strong></li>
</ul>
<h4>2019</h4>
<ul>
    <li>2019/12 çŸ¥è¡Œåˆä¸€ç‹é˜³æ˜ (Unity of Knowledge and Action: Wang Yangming)</li>
    <li>2019/9 å¦‚ä½•æœ‰æ•ˆé˜…è¯»ä¸€æœ¬ä¹¦ (How to Read a Book Effectively)</li>
    <li>2019/9 å¾®ä¹ æƒ¯ (Mini Habits)</li>
    <li>â­ <strong>2019/5 å¹²æ³• (A Passion for Success) by ç¨»ç››å’Œå¤«</strong></li>
</ul>

<h2 id="gallery">Gallery</h2>
<div class="image-gallery">
  <figure>
    <img src="assets/åƒå²›æ¹–éª‘è¡Œ.png" alt="Cycling at Qiandao Lake" />
    <figcaption>Cycling at Qiandao Lake</figcaption>
  </figure>
  <figure>
    <img src="assets/é’æµ·æ¹–éª‘è¡Œ.jpg" alt="Cycling at Qinghai Lake" />
    <figcaption>Cycling at Qinghai Lake</figcaption>
  </figure>
  <figure>
    <img src="assets/å¾’æ­¥.png" alt="Hiking" />
    <figcaption>Hiking</figcaption>
  </figure>
</div>
<style>
.image-gallery {
  display: flex;
  flex-wrap: wrap;
  gap: 15px;
  justify-content: center;
  align-items: flex-start; /* Align figures at the top */
  padding: 10px 0;
}
.image-gallery figure {
  margin: 0; /* Reset default figure margin */
  text-align: center; /* Center the caption text */
}
.image-gallery img {
  height: 150px; /* Set a fixed height for uniform look */
  width: auto; /* Allow width to scale based on aspect ratio */
  border-radius: 8px;
  box-shadow: 0 4px 8px rgba(0,0,0,0.1);
  transition: transform 0.2s;
  display: block; /* To remove any extra space below the image */
}
.image-gallery img:hover {
  transform: scale(1.05);
}
.image-gallery figcaption {
  margin-top: 8px; /* Space between image and caption */
  font-size: 0.9em;
  color: #555;
}
</style>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;">
                  This homepage is deployed on <a href="https://pages.github.com/">GitHub Pages</a>. Last updated: Oct 1, 2025.
                  <br> Â© 2025 Youzhe Song
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>

    <script>
      // Get the modal
      var modal = document.getElementById('myModal');

      // Get the image and insert it inside the modal - use its "alt" text as a caption
      var modalImg = document.getElementById("img01");
      var images = document.getElementsByClassName('publication-image');
      for (var i = 0; i < images.length; i++) {
        var img = images[i];
        img.onclick = function(){
          modal.style.display = "block";
          modalImg.src = this.src;
        }
      }

      // Get the <span> element that closes the modal
      var span = document.getElementsByClassName("close")[0];

      // When the user clicks on <span> (x), close the modal
      span.onclick = function() { 
        modal.style.display = "none";
      }
      
      // When the user clicks anywhere on the modal, close it
      modal.onclick = function(event) {
        if (event.target == modal) {
          modal.style.display = "none";
        }
      }
    </script>

  </body>
</html>