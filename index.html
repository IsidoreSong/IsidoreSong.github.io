<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Isidore Song</title>
    <meta name="author" content="Isidore Song">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/icon.png" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <style>
      /* Modal styles */
      .modal {
        display: none; 
        position: fixed; 
        z-index: 1001; 
        padding-top: 100px; 
        left: 0;
        top: 0;
        width: 100%; 
        height: 100%; 
        overflow: auto; 
        background-color: rgba(0,0,0,0.9);
        text-align: center;
      }
      .modal-content {
        margin: auto;
        display: block;
        width: 80%;
        max-width: 700px;
      }
      .modal-content {
        animation-name: zoom;
        animation-duration: 0.6s;
      }
      @keyframes zoom {
        from {transform:scale(0)}
        to {transform:scale(1)}
      }
      .close {
        position: absolute;
        top: 15px;
        right: 35px;
        color: #f1f1f1;
        font-size: 40px;
        font-weight: bold;
        transition: 0.3s;
      }
      .close:hover,
      .close:focus {
        color: #bbb;
        text-decoration: none;
        cursor: pointer;
      }
      .publication-image {
        cursor: pointer;
      }
    </style>
  </head>
  <body>
    <!-- The Modal -->
    <div id="myModal" class="modal">
      <span class="close">&times;</span>
      <img class="modal-content" id="img01">
    </div>

    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Youzhe Song (Isidore)
                </p>
                <p>
                  <!-- I am a Master's student at East China Normal University, advised by Prof. Feng Wang. -->
                  My research centers on building AI that not only performs well but also reasons in a way that is <strong>intuitive and trustworthy</strong> to humans.
                  <br><br>
                  I focus on two core questions:
                  <br>
                  1) How can we build models that have a <strong>human-intuitive, stepwise, and organic reasoning trajectory</strong>?
                  <br>
                  2) How can models <strong>understand and align information from different sources</strong> (e.g., images and text) in a human-like manner?
                </p>
                <p style="text-align:center">
                  <a href="mailto:yanfengz@outlook.com">‚úâÔ∏è yanfengz@outlook.com</a>
                  <br>
                  üìç ‰∏≠ÂõΩ‰∏äÊµ∑Êµ¶‰∏úÂº†Ê±ü
                </p>
                <p style="text-align:center">
                  <a href="CV/2026Fall_Youzhe_Song_CV_phd.html">üîó CV</a> (<a href="CV/2026Fall_Youzhe_Song_CV_phd.pdf">üìÑ PDF</a>) &nbsp;/&nbsp;
                  <a href="SOP/SOP.html">üîó SOP</a> (<a href="SOP/SOP.pdf">üìÑ PDF</a>) &nbsp;/&nbsp;
                  <a href="https://github.com/IsidoreSong">üíª Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/Youzhe Song.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/Youzhe Song.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <h2>Research</h2>
            <tr>
              <td style="width:100%;vertical-align:middle">
                <p>
                  My Ph.D. research plan is built on my experience in mechanism design and reflections on human cognition. I aim to focus on two primary capabilities of large models:
                </p>
                <p>
                  <strong>1. Building a Unified Semantic Space:</strong> My first goal is to study how to effectively map diverse information into a unified, interpretable latent space. This goes beyond cross-modal mapping‚Äîit underpins logical reasoning. I believe that efficient cross-modal semantic alignment is a first step toward foundational models that can comprehensively understand the world.
                </p>
                <p>
                  <strong>2. Realizing Structured Reasoning in Latent Space:</strong> After achieving semantic alignment, my next goal is to design structured, chain-of-thought-like reasoning trajectories within this unified latent space. I want models not only to produce answers but also to present a decomposable and traceable reasoning process.
                </p>
              </td>
            </tr>
          </tbody></table>
          <br>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <h2>Education</h2>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/ECNU.png" alt="ECNU Logo" width="100" style="display: block; margin-left: auto; margin-right: auto;"></td>
              <td width="75%" valign="center">
                <strong><span class="papertitle">East China Normal University</span></strong> (Project 985)
                <br> <em>Sept 2021 ‚Äì June 2024</em><br>  <strong>M.S. in Computer Science and Technology</strong>
                <br> GPA: 3.77/4.00 (Top 5%); Admitted via recommendation (waiver of entrance exam).
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/Donghua_University_logo.png" alt="Donghua University Logo" width="100" style="display: block; margin-left: auto; margin-right: auto;"></td>
              <td width="75%" valign="center">
                <strong><span class="papertitle">Donghua University</span></strong> (Project 211)
                <br> <em>Sept 2017 ‚Äì June 2021</em><br>  <strong>B.S. in Computer Science and Technology</strong>
                <br> GPA: 4.01/4.30; Rank: 2/180; Outstanding Graduate.
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/Purdue_University_Northwest.svg" alt="Purdue University Northwest Logo" width="100" style="display: block; margin-left: auto; margin-right: auto;"></td>
              <td width="75%" valign="center">
                <strong><span class="papertitle">Purdue University Northwest</span></strong>
                <br> <em>Aug 2019 ‚Äì Aug 2020</em><br>  <strong>Exchange Student &amp; Research Assistant</strong>
                <br> GPA: 3.90/4.00; Awarded full CSC scholarship; 1st Place, Notre Dame Data Hackathon.
              </td>
            </tr>
          </tbody></table>
          <br>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <h2>Publications</h2>
            <tr style="padding:20px;border-spacing:20px;">
              <td style="padding:20px;width:40%;vertical-align:middle">
                <img src="data/CoReFace.png" alt="CoReFace Project" width="100%" class="publication-image" style="border-style: none; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.3); transition: filter 0.3s ease;">
              </td>
              <td width="60%" valign="middle">
                <a href="https://doi.org/10.1016/j.patcog.2024.110483">
                  <span class="papertitle">CoReFace: Sample-guided Contrastive Regularization for Deep Face Recognition</span>
                </a>
                <br>
                <strong>Youzhe Song</strong>, Feng Wang
                <br>
                <em>Pattern Recognition (PR), 2024</em>
                <br>
                <a href="https://doi.org/10.1016/j.patcog.2024.110483">Paper</a> (<a href="data/CoReFace_PR_revised2.pdf">PDF</a>) /
                <a href="https://github.com/IsidoreSong/CoreFace">Code</a>
                <p></p>
                <p>A framework using contrastive learning as a regularizer to learn a more discriminative feature space, increasing the similarity margin for positive/negative pairs by 15% and achieving SOTA performance.</p>
              </td>
            </tr>
            <tr style="padding:20px;border-spacing:20px;">
              <td style="padding:20px;width:40%;vertical-align:middle">
                <img src="data/QGFace.png" alt="QGFace Project" width="100%" class="publication-image" style="border-style: none; box-shadow: 5px 5px 10px rgba(0, 0, 0, 0.3); transition: filter 0.3s ease;">
              </td>
              <td width="60%" valign="middle">
                <a href="https://arxiv.org/abs/2312.17494">
                  <span class="papertitle">QGFace: Quality-Guided Joint Training For Mixed-Quality Face Recognition</span>
                </a>
                <br>
                <strong>Youzhe Song</strong>, Feng Wang
                <br>
                <em>IEEE International Conference on Automatic Face and Gesture Recognition (FG), 2024</em>
                <br>
                <a href="https://arxiv.org/abs/2312.17494">Paper</a> (<a href="data/QGFace.pdf">PDF</a>) /
                <a href="https://github.com/IsidoreSong/QGFace">Code</a>
                <p></p>
                <p>A unified, single-encoder architecture with a quality-aware strategy to address the real-world issue of training a single model on heterogeneous-quality data, reaching SOTA on mixed-quality benchmarks.</p>
              </td>
            </tr>
          </tbody></table>
          <br>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <h2>Industry Experience</h2>
            <tr>
              <td style="padding:20px;width:15%;vertical-align:middle"><img src="images/wwec.jpg" alt="WWEC Logo" width="50" style="display: block; margin-left: auto; margin-right: auto;"></td>
              <td width="85%" valign="center">
                <strong><a href="https://www.wwec820.com/"><span class="papertitle">Worldwide Educators Conference (WWEC)</span></a></strong>
                <br> <em>June 2024 - Present</em><br>  <strong>Technical Manager</strong>
                <br> Managed technical associations and developed an automated tool to generate 1000+ custom conference assets, saving an estimated 100+ hours of manual design work.
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:15%;vertical-align:middle"><img src="images/qiyuan.jpg" alt="KeyoneAI Logo" width="50" style="display: block; margin-left: auto; margin-right: auto;"></td>
              <td width="85%" valign="center">
                <strong><a href="#"><span class="papertitle">Shanghai KeyoneAI Technology Co., Ltd.</span></a></strong>
                <br> <em>May 2023 - Oct 2023</em><br>  <strong>AI Full-Stack Developer Intern</strong>
                <br> Engineered a full-stack design tool by fine-tuning Stable Diffusion with LoRA and ControlNet to enable intuitive, controllable features like text-to-image and inpainting.
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:15%;vertical-align:middle"></td>
              <td width="85%" valign="center">
                <strong><a href="#"><span class="papertitle">Shanghai Feifan Technology Co., Ltd.</span></a></strong>
                <br> <em>May 2021 - Aug 2021</em><br>  <strong>AI Algorithm Intern</strong>
                <br> Developed a fashion aesthetics recommendation system leading to a 20% inventory reduction for the client by building a color block classification model and a rule-based engine.
              </td>
            </tr>
          </tbody></table>
          <br>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;">
                  This homepage is deployed on <a href="https://pages.github.com/">GitHub Pages</a>. Last updated: Oct 1, 2025.
                  <br> ¬© 2025 Youzhe Song
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>

    <script>
      // Get the modal
      var modal = document.getElementById('myModal');

      // Get the image and insert it inside the modal - use its "alt" text as a caption
      var modalImg = document.getElementById("img01");
      var images = document.getElementsByClassName('publication-image');
      for (var i = 0; i < images.length; i++) {
        var img = images[i];
        img.onclick = function(){
          modal.style.display = "block";
          modalImg.src = this.src;
        }
      }

      // Get the <span> element that closes the modal
      var span = document.getElementsByClassName("close")[0];

      // When the user clicks on <span> (x), close the modal
      span.onclick = function() { 
        modal.style.display = "none";
      }
      
      // When the user clicks anywhere on the modal, close it
      modal.onclick = function(event) {
        if (event.target == modal) {
          modal.style.display = "none";
        }
      }
    </script>

  </body>
</html>